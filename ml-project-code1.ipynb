{"cells":[{"metadata":{"_uuid":"54f800a8-1410-4778-8b8c-b30854bfdaf7","_cell_guid":"ca438948-3b2d-4a6a-8032-a78628d5588f","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns \nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nimport sys\nimport time\nimport lightgbm as lgb\nfrom catboost import CatBoostClassifier\nimport xgboost as xgb\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom IPython.display import HTML\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import log_loss\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.model_selection import train_test_split\nfrom hyperopt import fmin, tpe, hp, anneal, Trials\nimport hyperopt\nimport gc\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a99c0c6f-d775-4728-b22f-767e23ce857f","_cell_guid":"e2c7a67f-115e-4837-9e27-770696daf573","trusted":true},"cell_type":"code","source":"usecols = ['fecha_dato', 'ncodpers', 'ind_empleado', 'pais_residencia', 'sexo',\n        'age', 'fecha_alta', 'ind_nuevo', 'antiguedad', 'indrel',\n        'indrel_1mes', 'tiprel_1mes', 'indresi', 'indext',\n        'canal_entrada', 'indfall','nomprov', 'ind_actividad_cliente', 'renta', 'segmento',\n       'ind_ahor_fin_ult1', 'ind_aval_fin_ult1', 'ind_cco_fin_ult1',\n       'ind_cder_fin_ult1', 'ind_cno_fin_ult1', 'ind_ctju_fin_ult1',\n       'ind_ctma_fin_ult1', 'ind_ctop_fin_ult1', 'ind_ctpp_fin_ult1',\n       'ind_deco_fin_ult1', 'ind_deme_fin_ult1', 'ind_dela_fin_ult1',\n       'ind_ecue_fin_ult1', 'ind_fond_fin_ult1', 'ind_hip_fin_ult1',\n       'ind_plan_fin_ult1', 'ind_pres_fin_ult1', 'ind_reca_fin_ult1',\n       'ind_tjcr_fin_ult1', 'ind_valo_fin_ult1', 'ind_viv_fin_ult1',\n       'ind_nomina_ult1', 'ind_nom_pens_ult1', 'ind_recibo_ult1']\n\n# USECOLS ARE ALL THE COLUMNS THAT WE ARE USING FOR OUR PROJECT\n# WE HAVE DROPPED A TOTAL OF 4 COLUMNS WHICH WERE TOO SKEWED.\n\nusecols1 = ['fecha_dato', 'ncodpers', 'ind_empleado', 'pais_residencia', 'sexo','age', \n            'fecha_alta', 'ind_nuevo', 'antiguedad', 'indrel','indrel_1mes', 'tiprel_1mes',\n        'indresi', 'indext','canal_entrada', 'indfall','nomprov', 'ind_actividad_cliente', 'renta', 'segmento']\n\n# THESE ARE ALL THE FEATURE COLUMNS WE ARE USING.\n\nusecols2 = ['fecha_dato','ncodpers','ind_ahor_fin_ult1', 'ind_aval_fin_ult1', 'ind_cco_fin_ult1',\n       'ind_cder_fin_ult1', 'ind_cno_fin_ult1', 'ind_ctju_fin_ult1',\n       'ind_ctma_fin_ult1', 'ind_ctop_fin_ult1', 'ind_ctpp_fin_ult1',\n       'ind_deco_fin_ult1', 'ind_deme_fin_ult1', 'ind_dela_fin_ult1',\n       'ind_ecue_fin_ult1', 'ind_fond_fin_ult1', 'ind_hip_fin_ult1',\n       'ind_plan_fin_ult1', 'ind_pres_fin_ult1', 'ind_reca_fin_ult1',\n       'ind_tjcr_fin_ult1', 'ind_valo_fin_ult1', 'ind_viv_fin_ult1',\n       'ind_nomina_ult1', 'ind_nom_pens_ult1', 'ind_recibo_ult1']\n\n# THESE ARE ALL THE PRODUCT COLUMNS .","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"90e98c46-8483-4c5b-8280-8910c9c3c4b0","_cell_guid":"849db3fb-3f3a-4531-8127-259648739ba1","trusted":true},"cell_type":"markdown","source":"# **DATA LOADING**"},{"metadata":{"_uuid":"ecc5b032-8347-4217-8875-9e9bfd38b690","_cell_guid":"b8bfa84f-8f38-4747-a912-71d9f58f56a6","trusted":true},"cell_type":"code","source":"# LOADING OF TRAIN AND TEST DATA IN df and df_t respectively.\n\ndf = pd.read_csv('../input/santander-pr/train.csv',dtype={\"sexo\":str,\"ind_nuevo\":str,\"ult_fec_cli_1t\":str,\"indext\":str,\"ind_empleado\":\"category\",\"ind_nuevo\":\"category\",\"indrel\":\"category\",\"indrel_1mes\":\"category\",\"tiprel_1mes\":\"category\",\"indresi\":\"category\",\"indext\":\"category\",\"conyuemp\":\"category\",\"indfall\":\"category\",\"canal_entrada\":\"category\",\"ind_ahor_fin_ult1\":\"int8\",'ind_aval_fin_ult1':\"int8\", 'ind_cco_fin_ult1':\"int8\",'ind_cder_fin_ult1':\"int8\", 'ind_cno_fin_ult1':\"int8\", 'ind_ctju_fin_ult1':\"int8\",'ind_ctma_fin_ult1':\"int8\", 'ind_ctop_fin_ult1':\"int8\", 'ind_ctpp_fin_ult1':\"int8\",'ind_deco_fin_ult1':\"int8\", 'ind_deme_fin_ult1':\"int8\", 'ind_dela_fin_ult1':\"int8\",'ind_ecue_fin_ult1':\"int8\", 'ind_fond_fin_ult1':\"int8\", 'ind_hip_fin_ult1':\"int8\",'ind_plan_fin_ult1':\"int8\", 'ind_pres_fin_ult1':\"int8\", 'ind_reca_fin_ult1':\"int8\",'ind_tjcr_fin_ult1':\"int8\", 'ind_valo_fin_ult1':\"int8\", 'ind_viv_fin_ult1':\"int8\", 'ind_recibo_ult1':\"int8\"}, usecols=usecols)\ndf_t = pd.read_csv('../input/santander-pr/test.csv',dtype={\"sexo\":str,\"ind_nuevo\":str,\"ult_fec_cli_1t\":str,\"indext\":str,\"ind_empleado\":\"category\",\"ind_nuevo\":\"category\",\"indrel\":\"category\",\"indrel_1mes\":\"category\",\"tiprel_1mes\":\"category\",\"indresi\":\"category\",\"indext\":\"category\",\"conyuemp\":\"category\",\"indfall\":\"category\",\"canal_entrada\":\"category\"}, usecols=usecols1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"adf3b4e2-60b6-4132-9024-4e58d288c072","_cell_guid":"90405faa-bbcc-462b-b573-715c8359af45","trusted":true},"cell_type":"code","source":"# HERE WE ARE SORTING OUR DATA FOR USING LAGS AND TOGGLE FEATURES\n\ndf.sort_values(by=['ncodpers','fecha_dato'],inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1eaf558c-68bd-499c-9919-0b0c00ce21de","_cell_guid":"aec4060f-578b-4b5f-9ec1-1027f764ba7a","trusted":true},"cell_type":"markdown","source":"# **PRE-PROCESSING**"},{"metadata":{"_uuid":"ced593c6-d59d-42b6-a564-9a0250264b9c","_cell_guid":"dec2e2df-a074-480a-a64c-b2c42e1d3aec","trusted":true},"cell_type":"markdown","source":"**DROPPING OF ROWS AND ORGANISING COLUMNS**"},{"metadata":{"_uuid":"14fe529a-3bc4-4a35-85ac-55f12e7cdfaf","_cell_guid":"8771f0db-bfca-4699-b712-d02786f9ed6a","trusted":true},"cell_type":"code","source":"# WE Dropped around 27734 rows which had all its columns empty.\n\ndf=df[df['indrel'].notna()]\ndf=df.dropna(subset=['ind_empleado'])\n\n# Here we are converting our string dates into datetime datatype . \n\n#TRAIN\ndf[\"fecha_dato\"] = pd.to_datetime(df[\"fecha_dato\"],format=\"%Y-%m-%d\")\ndf[\"fecha_alta\"] = pd.to_datetime(df[\"fecha_alta\"],format=\"%Y-%m-%d\")\n\n#TEST\ndf_t[\"fecha_dato\"] = pd.to_datetime(df_t[\"fecha_dato\"],format=\"%Y-%m-%d\")\ndf_t[\"fecha_alta\"] = pd.to_datetime(df_t[\"fecha_alta\"],format=\"%Y-%m-%d\")\n\n# We are dropping antiguedad which refers to the seniority of a customer but rather we are using\n# a new column cust_since which is the numeric difference between fecha_alta and fecha_dato since antiguedad had\n# a lot of weird values.\n\n# TRAIN\ndf.drop(['antiguedad'],axis=1,inplace=True)\ndf['cust_since'] = df['fecha_dato'].dt.to_period('M').astype(int) - df['fecha_alta'].dt.to_period('M').astype(int)\n# TEST\ndf_t.drop(['antiguedad'],axis=1,inplace=True)\ndf_t['cust_since'] = df_t['fecha_dato'].dt.to_period('M').astype(int) - df_t['fecha_alta'].dt.to_period('M').astype(int)\n\n# In column indrel_1mes the data was not uniform for similar data, some in integer some in string so we converted\n# it using a dictionary.\nmap_dict = { 1.0  : \"1\",\n            \"1.0\" : \"1\",\n            \"1\"   : \"1\",\n            \"3.0\" : \"3\",\n            \"P\"   : \"P\",\n            3.0   : \"3\",\n            2.0   : \"2\",\n            \"3\"   : \"3\",\n            \"2.0\" : \"2\",\n            4.0   : \"4\",\n            \"4.0\" : \"4\",\n            \"4\"   : \"4\",\n            \"2\"   : \"2\"}\n\n# TRAIN\n\ndf.indrel_1mes = df.indrel_1mes.apply(lambda x: map_dict.get(x,x))\n# TEST\n\ndf_t.indrel_1mes = df_t.indrel_1mes.apply(lambda x: map_dict.get(x,x))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4ae282e4-6099-4c97-a1b7-9e03b764a2c5","_cell_guid":"0bbabd31-818e-4cfd-87c2-7bcb87017d4b","trusted":true},"cell_type":"markdown","source":"**REPLACING OF NULL VALUES**"},{"metadata":{"_uuid":"ab36c3d6-bdde-4814-b041-e0115ebca43d","_cell_guid":"abfd1cfb-88fb-4e58-ae53-ddb98a21a7fb","trusted":true},"cell_type":"code","source":"#We replaced the null values using 1\n\ndf.indrel_1mes.fillna(\"1\",inplace=True)  # TRAIN\ndf_t.indrel_1mes.fillna(\"1\",inplace=True) # TEST\n\n# FILLING OF NULL VALUES\n\n# WE HAVE FILLED THE NULL VALUES OF ALL COLUMNS USING THE MODE OF THE COLUMN.\n\n# TRAIN\n\ndf['ind_empleado'].fillna(\"N\",inplace=True)\ndf['pais_residencia'].fillna(\"ES\",inplace=True)\ndf['indresi'].fillna(\"S\",inplace=True)\ndf['indext'].fillna(\"N\",inplace=True)\ndf['indfall'].fillna(\"N\",inplace=True)\ndf['sexo'].fillna(df['sexo'].mode()[0], inplace=True)\ndf['segmento'].fillna(df['segmento'].mode()[0], inplace=True)\ndf['canal_entrada'] = df['canal_entrada'].astype('str')\ndf['canal_entrada'].fillna(\"UNK\",inplace=True)\ndf.tiprel_1mes.fillna(\"A\",inplace=True)\ndf['ind_nomina_ult1'].fillna(0,inplace=True)\ndf['ind_nom_pens_ult1'].fillna(0,inplace=True)\ndf.tiprel_1mes.replace(to_replace='N',value='A',inplace=True)\n\n# TEST\n\ndf_t['ind_empleado'].fillna(\"N\",inplace=True)\ndf_t['pais_residencia'].fillna(\"ES\",inplace=True)\ndf_t['indresi'].fillna(\"S\",inplace=True)\ndf_t['indext'].fillna(\"N\",inplace=True)\ndf_t['indfall'].fillna(\"N\",inplace=True)\ndf_t['sexo'].fillna(df_t['sexo'].mode()[0], inplace=True)\ndf_t['segmento'].fillna(df_t['segmento'].mode()[0], inplace=True)\ndf_t['canal_entrada'] = df_t['canal_entrada'].astype('str')\ndf_t['canal_entrada'].fillna(\"UNK\",inplace=True)\ndf_t.tiprel_1mes.fillna(\"A\",inplace=True)\ndf_t.tiprel_1mes.replace(to_replace='N',value='A',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"112172fb-6aae-455f-acdc-03a9afb1ecf3","_cell_guid":"86c867c9-482e-4bc3-b3c1-262d943d735a","trusted":true},"cell_type":"markdown","source":"**HANDLING OF NUMERICAL COLUMNS (REMOVING OUTLIERS AND NORMALISING)**"},{"metadata":{"_uuid":"379b9b79-75bf-4a6c-a644-33043715e2b2","_cell_guid":"cfda1572-bf3c-4c17-880e-dbe8f0f6f8f3","trusted":true},"cell_type":"code","source":"#NOW WE WILL HANDLE THE NUMERICAL COLUMNS OF RENTA,AGE and CUST_SINCE.\n\n# FIRST THE RENTA COLUMN.\n\n# FOR REPLACING THE NULL VALUES OF RENTA WE GROUP IT WITH THEIR RESPECTIVE PROVINCE'S MEAN.\n# AFTER THAT WE REMOVE OUTLIERS AT 75% QUANTILE MULTIPLIED BY 4 AND 25% QUANTILE DIVIDED BY 4.\n# THEN WE STANDARDISE THE COLUMN.\n\n# TRAIN\n\ndf['nomprov'].fillna(df['nomprov'].mode()[0], inplace=True)\ndf['renta']=df[['nomprov','renta']].groupby(['nomprov']).transform(lambda x: x.fillna(x.median())).renta\nmax_out=df.renta.quantile(0.75)*4\nmin_out=df.renta.quantile(0.25)/4\ndf.loc[df['renta']>max_out,'renta']=max_out\ndf.loc[df['renta']<min_out,'renta']=min_out\nscale=StandardScaler().fit(df[['renta']])\ndf[['renta']]=scale.transform(df[['renta']])\n\n# TEST \n\ndf_t['nomprov'].fillna(df_t['nomprov'].mode()[0], inplace=True)\ndf_t['renta']=df_t[['nomprov','renta']].groupby(['nomprov']).transform(lambda x: x.fillna(x.median())).renta\nmax_out=df_t.renta.quantile(0.75)*4\nmin_out=df_t.renta.quantile(0.25)/4\ndf_t.loc[df_t['renta']>max_out,'renta']=max_out\ndf_t.loc[df_t['renta']<min_out,'renta']=min_out\nscale=StandardScaler().fit(df_t[['renta']])\ndf_t[['renta']]=scale.transform(df_t[['renta']])\n\n\n# SECOND THE AGE COLUMN\n# WE REMOVE OUTLIERS OF AGES >95 and <12.\n# THEN WE USE NORMALIZATION , MIN-MAX TECHNIQUE.\n\n# TRAIN\n\ndf.age = pd.to_numeric(df.age,errors=\"coerce\")\nmax_out=df.age.quantile(0.75)*1.9\nmin_out=df.age.quantile(0.25)/2\ndf.loc[df['age']>max_out,'age']=max_out\ndf.loc[df['age']<min_out,'age']=min_out\nscale=MinMaxScaler().fit(df[['age']])\ndf[['age']]=scale.transform(df[['age']])\n\n# TEST\n\ndf_t.age = pd.to_numeric(df_t.age,errors=\"coerce\")\nmax_out=df_t.age.quantile(0.75)*1.9\nmin_out=df_t.age.quantile(0.25)/2\ndf_t.loc[df_t['age']>max_out,'age']=max_out\ndf_t.loc[df_t['age']<min_out,'age']=min_out\nscale=MinMaxScaler().fit(df_t[['age']])\ndf_t[['age']]=scale.transform(df_t[['age']])\n\n\n# THIRD THE CUST_SINCE COLUMN\n# WE NORMALISE THE COLUMNS, MIN-MAX TECHNIQUE.\n\n# TRAIN\n\nscale=MinMaxScaler().fit(df[['cust_since']])\ndf[['cust_since']]=scale.transform(df[['cust_since']])\n\n# TEST\n\nscale=MinMaxScaler().fit(df_t[['cust_since']])\ndf_t[['cust_since']]=scale.transform(df_t[['cust_since']])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4888c2a8-1d33-4e8c-bf51-1f7ccc3299cb","_cell_guid":"ab345376-e751-4114-b5a6-b0f253466c38","trusted":true},"cell_type":"markdown","source":"**CHANGING DATA TYPES**"},{"metadata":{"_uuid":"cb6981cc-02f1-4a73-ac00-8fcf64905784","_cell_guid":"17b205fd-bc2e-4cfa-9e01-7389cad4e48a","trusted":true},"cell_type":"code","source":"# NOW WE CHANGE DATA TYPES OF COLUMNS FOR BETTER RAM MANAGEMENT.\n\n# TRAIN\n\ndf.ind_nuevo=df.ind_nuevo.astype(np.float64)\ndf.indrel=df.indrel.astype(np.float64)\ndf.ind_actividad_cliente=df.ind_actividad_cliente.astype(np.int8)\ndf.ind_nuevo=df.ind_nuevo.astype(np.int8)\ndf.indrel=df.indrel.astype(np.int8)\ndf.ind_nomina_ult1=df.ind_nomina_ult1.astype(np.int8)\ndf.ind_nom_pens_ult1=df.ind_nom_pens_ult1.astype(np.int8)\ndf.ind_empleado=df.ind_empleado.astype(\"category\")\ndf.sexo=df.sexo.astype(\"category\")\n\n# TEST\n\ndf_t.ind_nuevo=df_t.ind_nuevo.astype(np.float64)\ndf_t.indrel=df_t.indrel.astype(np.float64)\ndf_t.ind_actividad_cliente=df_t.ind_actividad_cliente.astype(np.int8)\ndf_t.ind_nuevo=df_t.ind_nuevo.astype(np.int8)\ndf_t.indrel=df_t.indrel.astype(np.int8)\ndf_t.ind_empleado=df_t.ind_empleado.astype(\"category\")\ndf_t.sexo=df_t.sexo.astype(\"category\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4b2d8165-a7ac-46eb-8950-6d748cc55f7b","_cell_guid":"e69e2aba-9a0f-41b6-a940-05c74463458d","trusted":true},"cell_type":"markdown","source":"**REDUCING FEATURES IN CATEGORICAL COLUMNS**"},{"metadata":{"_uuid":"c3d60a15-7827-4fb4-b1d4-5c0c78fc98b7","_cell_guid":"0eef360e-184a-4b8d-90a6-834016002169","trusted":true},"cell_type":"code","source":"\n# IN MANY COLUMNS,WE HAD A LOT OF FEATURES AND IT WAS DIFFICULT TO ONE-HOT ENCODE THEM SO WE REDUCED THE NUMBER\n# OF FEATURES IN COLUMN TO BE FINITE IN 2 COLUMNS.\n\n# COLUMN CANAL_ENTRADA\n# WE REDUCED THE NUMBER OF FEATURES TO BE THE 10 MOST POPULAR FEATURES AND ALL THE REST TO BE IN OTH.\n\ncanal_name={'KHE' : 'KHE',\n            'KAT' : 'KAT',\n            'KFC' : 'KFC',\n            'KHQ' : 'KHQ',\n            'KFA' : 'KFA',\n            'KHK' : 'KHK',\n            'KHM' : 'KHM',\n            'UNK' : 'UNK',\n            'KHD' : 'KHD',\n            'KHN' : 'KHN'}\narr=list(df['canal_entrada'].unique())\n\nfor name in arr:\n    if(name not in canal_name.keys()):\n        canal_name[name]=\"OTH\"\n\narr=list(df_t['canal_entrada'].unique()) \n\nfor name in arr:\n    if(name not in canal_name.keys()):\n        canal_name[name]=\"OTH\"\n\ndf.canal_entrada = df.canal_entrada.apply(lambda x: canal_name.get(x,x))  # TRAIN\n\ndf_t.canal_entrada = df_t.canal_entrada.apply(lambda x: canal_name.get(x,x))  # TEST\n\n# COLUMN NOMPROV\n# WE REDUCED THE NUMBER OF FEATURES TO BE THE 10 MOST POPULAR FEATURES AND ALL THE REST TO BE IN OTH.\n\ncity_name={'MADRID' : 'MADRID',\n           'BARCELONA' : 'BARCELONA',\n           'VALENCIA' : 'VALENCIA',\n           'SEVILLA' : 'SEVILLA',\n           'CORUÃ‘A, A' : 'CORUNA',\n           'MURCIA' : 'MURCIA',\n           'MALAGA' : 'MALAGA',\n           'ZARAGOZA' : 'ZARAGOZA',\n           'ALICANTE' : 'ALICANTE',\n           'CADIZ' : 'CADIZ'}\narr=list(df.nomprov.unique())\nfor name in arr:\n    if(name not in city_name.keys()):\n        city_name[name]=\"OTH\"\n        \narr=list(df_t.nomprov.unique())\nfor name in arr:\n    if(name not in city_name.keys()):\n        city_name[name]=\"OTH\"\n        \ndf.nomprov = df.nomprov.apply(lambda x: city_name.get(x,x)) # TRAIN\n\ndf_t.nomprov = df_t.nomprov.apply(lambda x: city_name.get(x,x)) # TEST","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3b47f1df-3541-491d-8bc1-18e71c8e9820","_cell_guid":"f6eb0067-01cb-49b5-a468-96c0f51468c4","trusted":true},"cell_type":"markdown","source":"# **ENCODING AND MAKING OF DATAFRAMES**"},{"metadata":{"_uuid":"85831d7b-4b04-4865-9ce4-d1d4276439ae","_cell_guid":"784f13be-d407-4744-a36c-0f5fa19770a9","trusted":true},"cell_type":"code","source":"# MAKING OF df_train consisting of all feature columns from df dataframe. \n\ndf_train = df.loc[:,'fecha_dato':'segmento']\ndf_train['cust_since']=df['cust_since']\n\n# NOW WE DROP ANOTHER 6 COLUMNS BECAUSE THEY SHOWED NO IMPORTANCE IN OUR PLOT IMPORTANCE GRAPH.\n\ndrop=['ind_empleado','pais_residencia','indrel_1mes','indrel','indresi','indfall']\ndf_train.drop(columns=drop,inplace=True)\ndf_t.drop(columns=drop,inplace=True)\n\n# NOW WE DO ONE-HOT ENCODING ON OUR FEATURE COLUMNS.\n\ndf_train=pd.get_dummies(df_train,columns=['nomprov','sexo','ind_nuevo','indext','canal_entrada','ind_actividad_cliente','segmento','tiprel_1mes'])\n\ndf_test=pd.get_dummies(df_t,columns=['nomprov','sexo','ind_nuevo','indext','canal_entrada','ind_actividad_cliente','segmento','tiprel_1mes'])\n\n# df_y consists of all the target columns and few other important columns of which we find the lags and toggles.\n\ndf_y = df.loc[:,'ind_ahor_fin_ult1':'ind_recibo_ult1']\ndf_y['fecha_dato']=df['fecha_dato']\ndf_y['ncodpers']=df['ncodpers'] \ndf_y['ind_actividad_cliente']=df['ind_actividad_cliente']\ndf_y['segmento']=df['segmento']\n\n\n# NOW We have 3 dataframes df_train,df_test and df_y.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"76b34678-f61e-41ff-83a5-19776446fc1d","_cell_guid":"95654ccd-62fa-4092-b484-49261c20d8a3","trusted":true},"cell_type":"markdown","source":"# **FEATURE ENGINEERING**"},{"metadata":{"_uuid":"f26d350d-91bb-4aff-a060-9f03730a2eae","_cell_guid":"9041a3dd-ec84-42bd-b7ba-baea95aae803","trusted":true},"cell_type":"markdown","source":"***TEST DATA***"},{"metadata":{"_uuid":"727d92c1-b697-45ef-b9d9-d20227f29efc","_cell_guid":"a2999de2-d4c0-4024-859c-95b79bbc7720","trusted":true},"cell_type":"markdown","source":"**LAGS FOR TEST DATA**"},{"metadata":{"_uuid":"816e3da9-c6c6-4e12-9804-434296cbff15","_cell_guid":"26dbc1c4-ecbb-4351-ab96-165078d4470a","trusted":true},"cell_type":"code","source":"# We Have used few feature columns of lags and toggles.\n\n# Lags - Lag of 1 month,Lag of 2 month and Lag of 12 month and Lag of segmento and ind_actividad_cliente.\n\n# Toggle - Toggle of past 6 months.\n\n# These are the lags and toggles which we will merge with test data.\n\n# Lag of 1 month before.\n\ndf_1 = df[usecols2]\ndf_1 = df_1[df_train['fecha_dato']==\"2016-04-28\"]\n\n# Lag of 2 months before.\n\ndf_2 = df[usecols2]\ndf_2 = df_2[df_train['fecha_dato']==\"2016-03-28\"]\n\n# Lag of 12 months before.\n\ndf_12=df[usecols2]\ndf_12 = df_12[df_train['fecha_dato']==\"2015-05-28\"]\n\n# Lag for ind_actividad_cliente from 6 months ago \n\ndf_cliente=df[['fecha_dato','ncodpers','ind_actividad_cliente']]\ndf_cliente = df_cliente[df_train['fecha_dato']==\"2015-11-28\"]\n\n# Lag for segmento from 6 months ago\n\ndf_segmento=df[['fecha_dato','ncodpers','segmento']]\ndf_segmento = df_segmento[df_train['fecha_dato']==\"2015-11-28\"]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b7fb0dba-1b3c-4231-b33b-9b6bc130f132","_cell_guid":"236cae0e-41b7-495f-b221-f3294d53a5be","trusted":true},"cell_type":"markdown","source":"**TOGGLE OF LAST 6 MONTHS**"},{"metadata":{"_uuid":"17576a91-738d-4f96-97ce-7434b0232075","_cell_guid":"a345a86e-701b-4b08-976f-3951469efc3e","trusted":true},"cell_type":"code","source":"# Toggle of past 6 months ,We have 2 types of toggles -> 01_toggle and 10_toggle.\n\ndf_toggle=df[usecols2]\ndf_toggle=df_toggle[(df_train['fecha_dato']>=\"2015-10-28\") & (df_train['fecha_dato']<=\"2016-04-28\")]\nfor c in df_toggle.columns[2:]:\n    df_toggle[c+'_01_toggle']=0\n    df_toggle[c+'_10_toggle']=0\nfor c in usecols2[2:]:\n    df_toggle.loc[(df_toggle.fecha_dato==\"2016-04-28\") & (df_toggle.ncodpers==df_toggle.ncodpers.shift(1) ) & (df_toggle[c]!=df_toggle[c].shift(1)) & (df_toggle[c]==1) ,c+'_01_toggle']=df_toggle[c+'_01_toggle']+1\n    df_toggle.loc[(df_toggle.fecha_dato==\"2016-04-28\") & (df_toggle.ncodpers==df_toggle.ncodpers.shift(1) ) & (df_toggle[c]!=df_toggle[c].shift(1)) & (df_toggle[c]==0) ,c+'_10_toggle']=df_toggle[c+'_10_toggle']+1\n    df_toggle.loc[(df_toggle.fecha_dato==\"2016-04-28\") & (df_toggle.ncodpers==df_toggle.ncodpers.shift(2) ) & (df_toggle[c].shift(1)!=df_toggle[c].shift(2)) & (df_toggle[c].shift(1)==1) ,c+'_01_toggle']=df_toggle[c+'_01_toggle']+1\n    df_toggle.loc[(df_toggle.fecha_dato==\"2016-04-28\") & (df_toggle.ncodpers==df_toggle.ncodpers.shift(2) ) & (df_toggle[c].shift(1)!=df_toggle[c].shift(2)) & (df_toggle[c].shift(1)==0) ,c+'_10_toggle']=df_toggle[c+'_10_toggle']+1\n    df_toggle.loc[(df_toggle.fecha_dato==\"2016-04-28\") & (df_toggle.ncodpers==df_toggle.ncodpers.shift(3) ) & (df_toggle[c].shift(2)!=df_toggle[c].shift(3)) & (df_toggle[c].shift(2)==1) ,c+'_01_toggle']=df_toggle[c+'_01_toggle']+1\n    df_toggle.loc[(df_toggle.fecha_dato==\"2016-04-28\") & (df_toggle.ncodpers==df_toggle.ncodpers.shift(3) ) & (df_toggle[c].shift(2)!=df_toggle[c].shift(3)) & (df_toggle[c].shift(2)==0) ,c+'_10_toggle']=df_toggle[c+'_10_toggle']+1\n    df_toggle.loc[(df_toggle.fecha_dato==\"2016-04-28\") & (df_toggle.ncodpers==df_toggle.ncodpers.shift(4) ) & (df_toggle[c].shift(3)!=df_toggle[c].shift(4)) & (df_toggle[c].shift(3)==1) ,c+'_01_toggle']=df_toggle[c+'_01_toggle']+1\n    df_toggle.loc[(df_toggle.fecha_dato==\"2016-04-28\") & (df_toggle.ncodpers==df_toggle.ncodpers.shift(4) ) & (df_toggle[c].shift(3)!=df_toggle[c].shift(4)) & (df_toggle[c].shift(3)==0) ,c+'_10_toggle']=df_toggle[c+'_10_toggle']+1\n    df_toggle.loc[(df_toggle.fecha_dato==\"2016-04-28\") & (df_toggle.ncodpers==df_toggle.ncodpers.shift(5) ) & (df_toggle[c].shift(4)!=df_toggle[c].shift(5)) & (df_toggle[c].shift(4)==1) ,c+'_01_toggle']=df_toggle[c+'_01_toggle']+1\n    df_toggle.loc[(df_toggle.fecha_dato==\"2016-04-28\") & (df_toggle.ncodpers==df_toggle.ncodpers.shift(5) ) & (df_toggle[c].shift(4)!=df_toggle[c].shift(5)) & (df_toggle[c].shift(4)==0) ,c+'_10_toggle']=df_toggle[c+'_10_toggle']+1\n    df_toggle.loc[(df_toggle.fecha_dato==\"2016-04-28\") & (df_toggle.ncodpers==df_toggle.ncodpers.shift(6) ) & (df_toggle[c].shift(5)!=df_toggle[c].shift(6)) & (df_toggle[c].shift(5)==1) ,c+'_01_toggle']=df_toggle[c+'_01_toggle']+1\n    df_toggle.loc[(df_toggle.fecha_dato==\"2016-04-28\") & (df_toggle.ncodpers==df_toggle.ncodpers.shift(6) ) & (df_toggle[c].shift(5)!=df_toggle[c].shift(6)) & (df_toggle[c].shift(5)==0) ,c+'_10_toggle']=df_toggle[c+'_10_toggle']+1\ndrop=usecols2[2:]\ndf_toggle.drop(columns=drop,inplace=True)\ndf_toggle.fillna(0,inplace=True)\ndf_toggle=df_toggle[(df_train['fecha_dato']==\"2016-04-28\")]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"34e94f01-1645-43ef-9082-cf8ae124147e","_cell_guid":"4425afc7-c90d-47fb-8cc2-9937c27707d0","trusted":true},"cell_type":"markdown","source":"**RAM MANAGEMENT**"},{"metadata":{"_uuid":"715bd15d-9047-47f2-a9b9-0df36415c824","_cell_guid":"f2641a45-f351-421a-81e6-52cbdac568ef","trusted":true},"cell_type":"code","source":"# We delete df and df_t for RAM Management .\ndel(df)\ndel(df_t)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3f4eea9d-03e8-42a3-be61-19ed69d9533b","_cell_guid":"cc6fdda9-03c4-45b4-a07b-3dce29a36624","trusted":true},"cell_type":"markdown","source":"***TRAIN DATA***"},{"metadata":{"_uuid":"00da2e23-e4af-4897-9c9a-cf4dbeb97646","_cell_guid":"c053199a-bd5f-4d7c-97cf-4370500ffcb9","trusted":true},"cell_type":"markdown","source":"**REDUCING TIMEFRAME TO REQUIRED MONTHS**"},{"metadata":{"_uuid":"d8173c89-ee57-491b-b99c-5de4ed2507cf","_cell_guid":"f9944ed0-4231-4291-97ee-15bdfe59841f","trusted":true},"cell_type":"code","source":"# We are using data of only 1 month that is April 2016.\n# That is why we have taken only months which are needed for lags and toggles for April 2016.\n\ndf_train = df_train[((df_train['fecha_dato']==\"2015-04-28\"))  | ((df_train['fecha_dato']>=\"2015-09-28\") & (df_train['fecha_dato']<=\"2016-04-28\"))]\ndf_y = df_y[((df_y['fecha_dato']==\"2015-04-28\")) | ((df_y['fecha_dato']>=\"2015-09-28\") & (df_y['fecha_dato']<=\"2016-04-28\"))]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5bde2d78-6697-44e2-954b-e9b74e2cca75","_cell_guid":"4b9cffdd-8f1d-4338-9a11-883318cd5974","trusted":true},"cell_type":"markdown","source":"**ADDING TOGGLE DATA TO TRAIN**"},{"metadata":{"_uuid":"9b5a4fb2-613e-4d74-a46f-41aef5fa81d7","_cell_guid":"323a8b04-6d1e-4f95-978a-50bd0bd2b420","trusted":true},"cell_type":"code","source":"# Now we will do toggle for the past 6 months on train data.\n# Even here we have 2 types of toggles 01_toggle and 10_toggle.\n\nfor c in df_y.columns[:24]:\n    df_y[c+'_01_toggle']=0\n    df_y[c+'_10_toggle']=0\n\nfor c in df_y.columns[:24]:\n    df_y.loc[(df_y.fecha_dato==\"2016-04-28\") & (df_y.ncodpers==df_y.ncodpers.shift(2) ) & (df_y[c].shift(1)!=df_y[c].shift(2)) & (df_y[c].shift(1)==1),c+'_01_toggle']=df_y[c+'_01_toggle']+1\n    df_y.loc[(df_y.fecha_dato==\"2016-04-28\") & (df_y.ncodpers==df_y.ncodpers.shift(2) ) & (df_y[c].shift(1)!=df_y[c].shift(2)) & (df_y[c].shift(1)==0),c+'_10_toggle']=df_y[c+'_10_toggle']+1\n    df_y.loc[(df_y.fecha_dato==\"2016-04-28\") & (df_y.ncodpers==df_y.ncodpers.shift(3) ) & (df_y[c].shift(2)!=df_y[c].shift(3)) & (df_y[c].shift(2)==1),c+'_01_toggle']=df_y[c+'_01_toggle']+1\n    df_y.loc[(df_y.fecha_dato==\"2016-04-28\") & (df_y.ncodpers==df_y.ncodpers.shift(3) ) & (df_y[c].shift(2)!=df_y[c].shift(3)) & (df_y[c].shift(2)==0),c+'_10_toggle']=df_y[c+'_10_toggle']+1\n    df_y.loc[(df_y.fecha_dato==\"2016-04-28\") & (df_y.ncodpers==df_y.ncodpers.shift(4) ) & (df_y[c].shift(3)!=df_y[c].shift(4)) & (df_y[c].shift(3)==1),c+'_01_toggle']=df_y[c+'_01_toggle']+1\n    df_y.loc[(df_y.fecha_dato==\"2016-04-28\") & (df_y.ncodpers==df_y.ncodpers.shift(4) ) & (df_y[c].shift(3)!=df_y[c].shift(4)) & (df_y[c].shift(3)==0),c+'_10_toggle']=df_y[c+'_10_toggle']+1\n    df_y.loc[(df_y.fecha_dato==\"2016-04-28\") & (df_y.ncodpers==df_y.ncodpers.shift(5) ) & (df_y[c].shift(4)!=df_y[c].shift(5)) & (df_y[c].shift(4)==1),c+'_01_toggle']=df_y[c+'_01_toggle']+1\n    df_y.loc[(df_y.fecha_dato==\"2016-04-28\") & (df_y.ncodpers==df_y.ncodpers.shift(5) ) & (df_y[c].shift(4)!=df_y[c].shift(5)) & (df_y[c].shift(4)==0),c+'_10_toggle']=df_y[c+'_10_toggle']+1\n    df_y.loc[(df_y.fecha_dato==\"2016-04-28\") & (df_y.ncodpers==df_y.ncodpers.shift(6) ) & (df_y[c].shift(5)!=df_y[c].shift(6)) & (df_y[c].shift(5)==1),c+'_01_toggle']=df_y[c+'_01_toggle']+1\n    df_y.loc[(df_y.fecha_dato==\"2016-04-28\") & (df_y.ncodpers==df_y.ncodpers.shift(6) ) & (df_y[c].shift(5)!=df_y[c].shift(6)) & (df_y[c].shift(5)==0),c+'_10_toggle']=df_y[c+'_10_toggle']+1\n    df_y.loc[(df_y.fecha_dato==\"2016-04-28\") & (df_y.ncodpers==df_y.ncodpers.shift(7) ) & (df_y[c].shift(6)!=df_y[c].shift(7)) & (df_y[c].shift(6)==1),c+'_01_toggle']=df_y[c+'_01_toggle']+1\n    df_y.loc[(df_y.fecha_dato==\"2016-04-28\") & (df_y.ncodpers==df_y.ncodpers.shift(7) ) & (df_y[c].shift(6)!=df_y[c].shift(7)) & (df_y[c].shift(6)==0),c+'_10_toggle']=df_y[c+'_10_toggle']+1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6e05cba8-9c55-4557-986b-9269b1d7cb14","_cell_guid":"c1995d03-7c2b-4cb5-99a6-677ace3b0b2b","trusted":true},"cell_type":"markdown","source":"**REDUCING TIMEFRAME FURTHER FOR ONLY LAGS**"},{"metadata":{"_uuid":"d713d3c2-6f36-42fb-855b-0e8fadb27569","_cell_guid":"cc873707-c6b3-4c7b-a2b5-98d045ec83bc","trusted":true},"cell_type":"code","source":"# Now we reduce the timeframe even lesser for only the lags on train data.\n\ndf_train = df_train[((df_train['fecha_dato']==\"2015-04-28\"))  | (df_train['fecha_dato']==\"2015-10-28\") | ((df_train['fecha_dato']>=\"2016-02-28\") & (df_train['fecha_dato']<=\"2016-04-28\"))]\ndf_y = df_y[((df_y['fecha_dato']==\"2015-04-28\")) | (df_y['fecha_dato']==\"2015-10-28\") | ((df_y['fecha_dato']>=\"2016-02-28\") & (df_y['fecha_dato']<=\"2016-04-28\"))]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8b067cf6-5853-436e-8027-dd38ce5cd539","_cell_guid":"c3eb42e2-3647-41ad-a7d6-0a4e75e5f598","trusted":true},"cell_type":"markdown","source":"**LAGS ON TRAIN DATA**"},{"metadata":{"_uuid":"954ac7ef-088e-41f8-9742-bdf5c499d9eb","_cell_guid":"07d30a6a-3e7f-4c4b-86e2-224706c95848","trusted":true},"cell_type":"code","source":"# Now we do lags on the train data.\n\nfor c in df_y.columns[:24]:\n    df_y.loc[df_y.ncodpers==df_y.ncodpers.shift(1),c+'_lag1']=df_y[c].shift(1)\n    df_y.loc[df_y.ncodpers==df_y.ncodpers.shift(2),c+'_lag2']=df_y[c].shift(2)\n    df_y.loc[df_y.ncodpers==df_y.ncodpers.shift(4),c+'_lag12']=df_y[c].shift(4)\n\ndf_y.loc[df_y.ncodpers==df_y.ncodpers.shift(3),'ind_actividad_cliente'+'_lag']=df_y['ind_actividad_cliente'].shift(3)\n\ndf_y.loc[df_y.ncodpers==df_y.ncodpers.shift(3),'segmento'+'_lag']=df_y['segmento'].shift(3)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"19c6f50e-8bfc-4f2a-a351-3c6067fb1681","_cell_guid":"974bdc18-ed64-4c45-9501-09143a7c520a","trusted":true},"cell_type":"markdown","source":"**REDUCING OUR TIMEFRAME TO ONLY THE TRAINING MONTH**"},{"metadata":{"_uuid":"bd3ec2b5-2823-40eb-acba-1c67be0306bc","_cell_guid":"d218bba2-ddd2-4fad-a4e3-7335509635e2","trusted":true},"cell_type":"code","source":"# Now We reduce our timeframe only on our training month which is April 2016.\n\ndf_train = df_train[((df_train['fecha_dato']==\"2016-04-28\"))]\n\ndf_y = df_y[((df_y['fecha_dato']==\"2016-04-28\"))]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"de396db1-d5a5-4b48-878e-e8ba125a548d","_cell_guid":"4f794e25-3171-4b92-a410-d9a860116bda","trusted":true},"cell_type":"markdown","source":"1. **MERGING THE LAGS AND TOGGLE DATA TO OUR TEST DATA**\n2. **WE WANTED TO DO IT UP AT THE PLACE WHERE WE DEFINED THE DATAFRAMES FOR LAGS AND TOGGLE BUT WE WERE**\n**FACING RAM ISSUES**"},{"metadata":{"_uuid":"0efff75c-976a-47aa-8af5-2955f9310ed4","_cell_guid":"f770bceb-9fef-4545-8610-c2b4a3fa3366","trusted":true},"cell_type":"code","source":"# RENAMING OF LAG COLUMNS BEFORE MERGING INTO TEST DATA.\n\nfor c in df_1.columns[2:]:\n    df_1.rename(columns={c:c+\"_lag1\"}, inplace=True)\n\nfor c in df_2.columns[2:]:\n    df_2.rename(columns={c:c+\"_lag2\"},inplace=True)\n\nfor c in df_12.columns[2:]:\n    df_12.rename(columns={c:c+\"_lag12\"},inplace=True)\n\ndf_cliente.rename(columns={'ind_actividad_cliente': 'ind_actividad_cliente' + '_lag'},inplace=True)\n\ndf_segmento.rename(columns={'segmento': 'segmento' + '_lag'},inplace=True)\n\n# MERGING OF TOGGLE DATA AND LAG DATA INTO TEST DATA\n\ndf_test=df_test.merge(df_1.loc[:, 'ncodpers':], on='ncodpers', how='left')\ndf_test=df_test.merge(df_2.loc[:, 'ncodpers':], on='ncodpers', how='left')\ndf_test=df_test.merge(df_12.loc[:, 'ncodpers':], on='ncodpers', how='left')\ndf_test=df_test.merge(df_toggle.loc[:, 'ncodpers':], on='ncodpers', how='left')\ndf_test=df_test.merge(df_cliente.loc[:, 'ncodpers':], on='ncodpers', how='left')\ndf_test=df_test.merge(df_segmento.loc[:, 'ncodpers':], on='ncodpers', how='left')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"133cb996-16fb-4434-bc9e-3b344face736","_cell_guid":"6bf9c274-f691-44a6-a826-9f766dd1b453","trusted":true},"cell_type":"markdown","source":"**REMOVING NULL VALUES AND OTHER PROCESSING IN THE NEWLY ADDED COLUMNS**"},{"metadata":{"_uuid":"35e5c335-f2e0-49bf-a339-20d92526d92e","_cell_guid":"9a5795f8-a4e8-451a-b888-678a12bf1a01","trusted":true},"cell_type":"code","source":"# NOW WE WILL FILL NULL DATA IN THE NEW COLUMNS ADDED IN TRAIN AND TEST DATA\n\n# TRAIN\n\ndf_y.loc[df_y.ind_actividad_cliente_lag.isnull()==True,'ind_actividad_cliente_lag']=df_y.ind_actividad_cliente\ndf_y.loc[df_y.segmento_lag.isnull()==True,'segmento_lag']=df_y.segmento\ndf_y.fillna(0,inplace=True)\n\n# TEST\n\ndf_test.loc[(df_test.ind_actividad_cliente_lag.isnull()==True) & (df_test.ind_actividad_cliente_0==1),'ind_actividad_cliente_lag']=0\ndf_test.loc[(df_test.ind_actividad_cliente_lag.isnull()==True) & (df_test.ind_actividad_cliente_1==1),'ind_actividad_cliente_lag']=1\ndf_test.loc[(df_test.segmento_lag.isnull()==True) & (df_test['segmento_01 - TOP']==1) ,'segmento_lag']='TOP'\ndf_test.loc[(df_test.segmento_lag.isnull()==True) & (df_test['segmento_02 - PARTICULARES']==1) ,'segmento_lag']='PARTICULARES'\ndf_test.loc[(df_test.segmento_lag.isnull()==True) & (df_test['segmento_03 - UNIVERSITARIO']==1) ,'segmento_lag']='UNIVERSITARIO'\ndf_test.fillna(0,inplace=True)\n\n# CHANGING DATA TYPE OF NEW COLUMNS\n\nfor c in df_y.columns[28:149]:\n    df_y[c]=df_y[c].astype(\"int8\")\n\nfor c in df_test.columns[8:163]:\n    df_test[c]=df_test[c].astype(\"int8\")\n    \n# CONVERTING STRING DATA INTO NUMERICALS.\n\nconvert={\"02 - PARTICULARES\" : 1,\n         \"PARTICULARES\" : 1,\n         \"03 - UNIVERSITARIO\" : 2,\n         \"UNIVERSITARIO\" : 2,\n         \"01 - TOP\" : 3,\n         \"TOP\" : 3}\n\ndf_y.segmento_lag = df_y.segmento_lag.apply(lambda x: convert.get(x,x))\n\ndf_test.segmento_lag = df_test.segmento_lag.apply(lambda x: convert.get(x,x))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"55d1a2ae-9c09-48e8-87ff-99b5c344da2a","_cell_guid":"2a934b09-ef69-4962-9a3c-a868bdf8f1ff","trusted":true},"cell_type":"markdown","source":"**SOME FINAL WORK NEEDED TO DO BEFORE TRAINING**"},{"metadata":{"_uuid":"e25993b5-de06-47eb-835f-b7072673277a","_cell_guid":"4bfdd49c-1e5a-4c44-b6c7-eab1db9fe82c","trusted":true},"cell_type":"code","source":"# SHIFTING OF ALL THE LAGS AND TOGGLES FROM df_y to df_train\n\nfor c in df_y.columns[26:]:\n    df_train[c]=df_y[c]\n    df_y.drop(columns=c, inplace=True)\n\n# REALIGINING OF COLUMNS OF TRAIN AND TEST DATA\n\ncol=df_test.columns\ndf_train=df_train[col]\n\n# MAKING OF THE result dataframe.\n\nresult=pd.DataFrame()\nresult['ncodpers']=df_test['ncodpers']\n\n# DROPPING OF COLUMNS WHICH ARE NOT NEEDED IN TRAINING PHASE.\n\ndf_train.drop(columns=['fecha_dato','ncodpers', 'fecha_alta'], inplace=True)\ndf_test.drop(columns=['fecha_dato','ncodpers', 'fecha_alta'],inplace=True)\ndf_y.drop(columns=['fecha_dato'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d0ca80c4-15b6-4b72-953f-c79a92b413cf","_cell_guid":"3c1ae5b8-2b7d-4ccd-b405-878f680e9566","trusted":true},"cell_type":"markdown","source":"# **TRAINING**"},{"metadata":{"_uuid":"3b15d8c4-e141-4c1d-8a1c-5c233124dbca","_cell_guid":"ee03cd9f-1bb5-4c9c-a076-7e8c4acc84ce","trusted":true},"cell_type":"markdown","source":"**MODEL SELECTION**"},{"metadata":{"_uuid":"9c9050e5-6677-43c0-a9ff-b1d8f6e1802e","_cell_guid":"b4a705b9-7bfa-4207-8307-668029576f21","trusted":true},"cell_type":"code","source":"# MODEL USED FOR THIS PART OF TRAINING\n\nclf = CatBoostClassifier(iterations=300,\n                        learning_rate=0.035,\n                        depth=12,\n                        loss_function='Logloss',\n                        min_data_in_leaf=25,\n                        rsm=0.42)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c9578d38-fbe7-4e4c-88b1-9d74b3eaf782","_cell_guid":"7f897070-9175-46ec-9576-332e7099866e","trusted":true},"cell_type":"markdown","source":"**FINAL TRAINING**"},{"metadata":{"_uuid":"424a66f0-b617-4fef-a366-9f351b82b75e","_cell_guid":"27d591fe-b519-4273-b4e1-78a085b3462d","trusted":true},"cell_type":"code","source":"# TRAINING FOR OUR DATA\n\nfor c in df_y.columns[:-1]:\n    y_train = df_y[c]\n    clf.fit(df_train, y_train)\n    p_train=clf.predict_proba(df_test)[:,1]\n    result[c]=p_train\n    print(c)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result.to_csv('result_old.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}